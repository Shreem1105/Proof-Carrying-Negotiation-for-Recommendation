{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# PCN-Rec: Proof-Carrying Negotiation for Recommendation\n",
                "\n",
                "This notebook runs the full pipeline for the \"Proof-Carrying Negotiation\" project.\n",
                "\n",
                "**Steps:**\n",
                "1. Setup (Install dependencies, Clone repo)\n",
                "2. Step 1: Data Prep & Candidate Generation (LightFM)\n",
                "3. Step 2: PCN-Rec Experiment (Single LLM vs PCN vs Ablations)\n",
                "4. Evaluation & Results\n",
                "\n",
                "**Requirements:**\n",
                "- Google Gemini API Key"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Install Dependencies\n",
                "!pip install google-genai lightfm numpy pandas scipy pyyaml pyarrow tqdm scikit-learn tenacity pydantic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Clone Repository\n",
                "import os\n",
                "if not os.path.exists('pcn-rec'):\n",
                "    !git clone https://github.com/Shreem1105/Proof-Carrying-Negotiation-for-Recommendation.git pcn-rec\n",
                "os.chdir('pcn-rec')\n",
                "print(\"Current working directory:\", os.getcwd())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Set Gemini API Key\n",
                "import os\n",
                "from google.colab import userdata\n",
                "\n",
                "try:\n",
                "    os.environ[\"GEMINI_API_KEY\"] = userdata.get('GEMINI_API_KEY')\n",
                "    print(\"API Key loaded from Secrets.\")\n",
                "except:\n",
                "    print(\"API Key not found in Secrets. Please input below:\")\n",
                "    key = input(\"Enter Gemini API Key: \")\n",
                "    os.environ[\"GEMINI_API_KEY\"] = key"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Step 1: Foundation (Data & Candidates)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prepare Data (MovieLens 100K)\n",
                "!python scripts/step1_prepare_data.py --config config/config.yaml --run_id paper_exp"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train Candidate Model (LightFM)\n",
                "!python scripts/step1_train_candidates.py --config config/config.yaml --run_id paper_exp"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate Top-100 Candidates (for all users)\n",
                "!python scripts/step1_generate_candidates.py --config config/config.yaml --run_id paper_exp"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Step 2: PCN-Rec Experiment\n",
                "\n",
                "We will run the experiment for a subset of users to demonstrate functionality. For the full paper results, remove `--max_users`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CONFIGURATION\n",
                "MAX_USERS = 50 # Set to None for full run (WARNING: Takes time and API quota)\n",
                "RUN_ID = \"paper_exp\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Baseline: Single LLM Reranker\n",
                "!python scripts/step2_run_single_llm_baseline.py --config config/config.yaml --run_id {RUN_ID} --max_users {MAX_USERS}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. PCN-Rec (Negotiation + Verifier)\n",
                "!python scripts/step2_run_pcnrec.py --config config/config.yaml --run_id {RUN_ID} --max_users {MAX_USERS}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Ablations\n",
                "!python scripts/step2_run_ablations.py --config config/config.yaml --run_id {RUN_ID} --max_users {MAX_USERS}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Evaluation & Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python scripts/step2_evaluate.py --config config/config.yaml --run_id {RUN_ID}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import os\n",
                "\n",
                "summary_path = f\"outputs/{RUN_ID}/evaluation_summary.csv\"\n",
                "if os.path.exists(summary_path):\n",
                "    df = pd.read_csv(summary_path)\n",
                "    display(df)\n",
                "else:\n",
                "    print(\"Evaluation summary not found.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}